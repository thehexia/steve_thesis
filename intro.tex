\chapter{INTRODUCTION} \label{ch:intro}

% FIXME: The introduction needs to flow. Don't break it up into this kind of
% question and answer dialog, and don't skimp on motivation. Take this guy's
% PhD thesis as an example:
%
% http://www.cs.colostate.edu/~christos/thesis/chp1.pdf
%
% It's a little more detailed than you'll need, but it's a good example of
% how to motivate the problem and organize both the solution and your
% contributions.

% FIXME: Use \emph to emphasize terms, not boldface.

The Internet is nowadays ubiquitous with everyday life. In the last twenty
years,
the industry has rapidly evolved to incorporate all kinds of new Internet
services:
cloud services, web services, Internet of Things, etc. As the world grows
more reliant on services provided over a network, so must the communication network evolve.

The backbone of all networks is the \emph{switch}. The term switch here is not used to specifically mean a Layer 2 forwarding device. but rather to mean any device capable of making forwarding decisions across multiple layers of the OSI stack \cite{osi_model}. The term switch thus incorporates bridges, routers, hardware firewalls, etc.
Unfortunately, modern switches suffer from a number of issues which make them difficult to use in an industry where networks are becoming increasingly elaborate.

Conventional switches are complex and unscalable because they are only designed to deal with very specific sets of well-known protocols and use cases. A router, for example, may be reconfigured with new forwarding rules, but it will never be anything other than a router. The behavior is difficult if not impossible to change, making these devices very rigid.
Because they may only be reconfigured within a limited use case, they cannot easily adapt to dynamic changes in network traffic and load.
Even when reconfigured, network administrators are often forced to do so through clunky, vendor-imposed command line interfaces. 

This model cannot last forever. Future networks will require that network flows be directed in increasingly complex ways. More protocols and information will be carried on packets than ever before, and the modern switch model simply is simply not flexible enough.
In order to bypass this inflexibility, it must be possible to implement network functions (routing, firewalls, NAT, etc) through intelligent networking applications in software.
These applications must be capable of automatically adapting to changing network conditions by modifying switch behavior to optimize forwarding decisions, throughput, resource consumption, etc.
There must also exist a switch which is capable of installing and running this software.

This is the promise of \emph{software-defined networking} (SDN). 
SDN modifies two major elements of a conventional network switch: the data plane and the control plane. The \emph{data plane}, sometimes called the \emph{forwarding plane}, is the element which is responsible for forwarding packets between ports on the device. The control plane is the element which learns and configures the forwarding logic used by the data plane. It is also capable of processing packets which the data plane cannot.

The Open Network
Foundation (ONF) defines SDN as the ``separation of the network control
plane from the forwarding [data] plane'' \cite{onf_sdn_def}.
Either of these components may then be implemented in regular software.
The goal of SDN architectures is to provide highly programmable, scalable, and 
efficient network functions in software.

The conventional control plane is replaced by a software application known as a \emph{controller} (software control plane).
This controller then serves as the intelligent network application which manages the switch's behavior. Alternatively, it may serve as an interface so that multiple network applications may manage the switch.
This software controller may be run on any machine, completely separate from its switch and data plane.
It may then perform distributed control over multiple data planes by communicating via network messages.
The most widely adopted standard for this communication is OpenFlow
\cite{openflow_spec}.
Because the software controller may be run on any machine,
any programmer can write regular software for common operating
systems and processors to control the behavior of their networking device.

The \emph{programmable data plane} remains on the device and may be implemented with specialized hardware. Alternatively, the data plane may be implemented in software that virtualizes underlying switch hardware.
A programmable data plane provides
two key benefits that the software control plane cannot: low-latency,
customizable packet processing and \emph{protocol independence}.

%In the control and data plane relationship,
%the control plane is smart but slow, while the data plane is fast yet dumb.
%That is,
%the control plane can perform general purpose computing but communicating with
%it has high latency. The data plane, on the other hand, is the fast path for
%packet processing.
%It has very limited computing power, but can process packets at a low latency.
%As programmable data planes evolve and support more flexible instruction sets,
%communicating with the control plane becomes less necessary.

%The software control plane supports general purpose computing using heavyweight
%processors. However, general purpose computing is slow and communicating
%with the control plane over a network using messages is even slower.
%Data planes, on the other hand, can process packets incredibly fast since
%they are designed for this single role, but do not necessarily support
%the full range of general purpose operations.
%If data planes could support more kinds of computation, then they can rely less
%on
%slow control planes, and delegate only under the more extreme circumstances.

Protocol independence means that a networking device is not required, by default, to support
a suite of well-known protocols (ethernet, IPv4, TCP, etc).
Rather than relying on specialized hardware or firmware tailored towards
parsing/decoding
these protocols, the data plane supports processors
and generic instructions that can be used to decode and operate on
any header and field.
This allows users to support their own protocols in addition to
supporting well-known protocols. This makes the data plane scalable, that is, it
can adapt to new headers easily.

%Intelligence implies that a machine or program is capable of performing a myriad of general purpose computations which one might find on normal CPU. 
%Consider a router for example. These machines are said to be intelligent because of the algorithms they use to route traffic across multiple networks. They may even support intelligent load and content balancing. But are they really intelligent compared to what modern computers are capable of? 
%
%Of course not. Modern devices use specialized hardware to process network traffic at maximum speeds, but as a trade-off, they lose the ability to perform general purpose computation that would support implementing intelligent network functions. Why is this so important?
%
%Network traffic can carry data which is completely inaccessible to many modern switches because they are incapable of processing everything. Consider how powerful it would be if any application could be installed on a network switch.




%Modern routers and switches provide the backbone for the Internet.
%These modern devices implement two fundamental components in their firmware: the
%\emph{data plane} and the \emph{control plane}. A control plane can be thought of as the brains of a network device, whereas the
%data plane is the brawn.
%
%The data plane is responsible for processing packet content and and moving them across the right ports.
%It makes fast forwarding decisions by using lookup tables to determine
%where a packet is sent. When it does
%not know how to handle a packet, it sends it to the control plane.
%
%A control plane manages its data plane.
%It is responsible for installing forwarding logic for a network device and is
%capable of learning new forwarding behaviors in response to unexpected packets.
%It does this by modifying the lookup tables used by the data plane.
%Together, the control and data plane implement \emph{network functions}, i.e.
%switching, NAT, firewall, etc.
%
%This model continues to be the most popular for switch development.
%However,
%this conventional type of networking has become too rigid, unscalable, and
%proprietary to support evolving technologies. 
%
%Defining network functionality in firmware is inherently inflexible.
%Firmware is architecture-dependent, difficult to write, and challenging to
%update
%regularly.
%Conventional switches are unscalable because they must deal with most or all
%common protocol headers.
%With dozens of common protocols now, and potentially dozens more in the future,
%it becomes evident that this model cannot last forever.
%Additionally, many devices are black boxes,
%only exposing an interface designed by the vendor,
%making them difficult to customize for enterprises with special needs.
%By extension, these black box devices force any network functions
%defined over them to be extremely architecture dependent.
%Due to these issues and others, a new paradigm for networking was created. 
%
%This new paradigm
%is called \textit{software-defined networking} (SDN). 

\section{Motivation: A Language for Programming SDN Devices}

In order to pursue programmable SDN devices, there must be a language to write
programs that process packets and define network functions. 
A number of language solutions arise here.
Some attempt to solve this problem by providing APIs for existing programming
languages (specifically C).
Others attempt to produce domain-specific languages (DSLs) for SDN devices.

The focus of this thesis is one such DSL, \emph{Steve}, a language for the safe
and
efficient specification of packet processing and network functions 
for programmable SDN switches. DSL provide one key benefit that low-level
languages cannot: safety.

A network program must be safe to execute more than anything else.
Network programs, especially those running on high-traffic devices, must not
crash due to logical mistakes or unnoticed undefined behaviors.
At best, this produces expensive network downtime; at worst, this
opens the way for security vulnerabilities on the device: 
denial of service attacks, buffer overflows, etc.

Typical packet processing programs are written in low-level languages, most
commonly C. These C programs usually work with data plane programming APIs such
as Open Data Plane (ODP) \cite{odp_webpage} and the Data Plane Programming Kit
(DPDK) \cite{dpdk_webpage}. Unfortunately, programming network devices in C can be prone
to errors stemming from buffer and resource management. 
These issues are compounded by the fact C is a general
purpose language not tailored towards packet processing, thus the burden of
safety
is left to the programmer, with no compiler to double check their code.
Specifically, C programs risks errors such as:

\begin{itemize}
\item accessing memory outside the bounds of a packet buffer or within a
constrained
region of memory,

\item writing bytes which exceed a constrained subset of the packet
resulting in a buffer overflow (i.e. writing new bytes into a header field
but exceeding the size of that field),

\item buffer underflow when not writing enough bytes when modifying
a field,

\item using a field in an operation that is not supported by its
range of values,

\item non-terminating cycles in program logic (infinite loops
triggered by a single packet),

\item incorrect assumptions about decoding state. That is, a programmer using
a field which they have not extracted yet.
\end{itemize}

Programmers using C for SDN applications are also burdened with management of
device resources. Specifically, a C programmer must manage:

\begin{itemize}
\item memory. The programmer must manage their own buffers for holding packet
data and packet meta data. This opens the opportunity for accidental
memory leakage.

\item ports. The programmer is responsible for receiving, reading, and
forwarding
through ports. This process should be decoupled from the packet processing logic
for modularity. A packet processing application should be architecture
independent
whereas port management is a architecture dependent problem.
\end{itemize}

% Low-level packet processing code can be very light on easy to understand
% abstraction and very heavy on gritty implementation details. The programmer
% should be focusing on high-level abstractions; concepts such as: what fields
%are
% needed, what operations must be performed on these fields, conditional
%decision
% making, packet classification, etc. Instead, they are worried about the many
% common ailments of writing in low-level code.
%
% The programmer must deal with resource allocation and management. They must
%deal
% with allocating their own buffers for storing packets and by extension must
%deal
% with de-allocating those buffers. This type of resource management is prone to
% accidental memory leakage, especially in C. Memory leakage of gigabytes of
%data
% will quickly bring a system down.
%
% The programmer must directly manage ports. They are also responsible for
% manually receiving, reading, and sending packets on those ports. This is code
%is
% common to all packet processing applications. The programmer should not be
% burdened with this kind of common code when writing a packet processor.
%
% When working with packet headers, the programmer must manually work with raw
% arrays of bytes. The burden of decoding fields from byte arrays and
%interpreting
% the value of those fields is shifted onto the programmer. Manual decoding can
%be
% a painful process on its own. It is prone to error, particularly off-by-N
% errors. When reinterpreting those bytes into header data structures, the
%result
% can be disastrous if the bytes are wrong or the data structure is wrong.
%Moving
% or copying those bytes around is particularly prone to buffer overflows.
%
% A number of other common problems come up when working in low-level code.
% Undefined behavior from reading past the end of packet buffers can be one.
% Performing operations on null pointers, invalid pointers, or uninitialized
% memory is another.
%
% Steve and its runtime, Flowpath, attempt to remedy most of these problems. The
% objective is to abstract many of these low-level details. Instead, the
% programmer only focuses on the high-level abstractions. Specifically, the
%Steve
% language focuses the programmer on writing the packet processing pipeline and
% makes the grittier details opaque

\section{Motivation: Programming a Single Network Device}

Steve focuses on the language features required for programming a single device. There must be a well-designed abstract machine for programming network applications on one switch before expanding to incorporate distributed control.

There are flaws in distributed control that a single device does not have to deal with.
Specifically, communicating with a distributed control plane is slow.
The switch has to send messages over a network, the controller must process the message, then send more messages back to modify switch behavior. This latency is unnecessary
The trade-off is that it allows for control over an
entire network.

A non-distributed control plane, on the other hand, has much
better performance.
It can exist on the
same hardware as the data plane and has little communication latency
because the two elements may communicate directly through an application
binary interface (ABI).
This model is considerably more effective for simple network functions.
The programming model for a control and data plane on the same device
is essentially basic event-driven programming (EDP).

The data plane raises events when it needs something from the control plane.
The control plane catches these events with special handlers and modifies the
forwarding logic accordingly.
A free benefit of this model is that a single language like Steve may
be used to define both control and data plane elements for a given 
device. 
 
\section{The Steve Programming Language}

The Steve programming language was designed to solve the problem of safe and efficient programming of SDN devices.
Steve is used for writing applications that define packet processing
and network functions on SDN devices.
It is protocol independent, strongly-typed,
and declarative.

Steve provides the mechanisms for defining \emph{packet
processing pipelines}, the core component used by a data plane
to process packet content and make forwarding decisions.
It also provides the ability to define \emph{event handlers} --
control plane functions which process unexpected packets and
modify the data plane when necessary.

\subsection{Packet Processing Pipelines}

The packet processing pipeline is a data plane algorithm that
uses multiple, smaller processing stages to decode packet content and make
forwarding decisions.
The Steve pipeline is a generalization
of the pipeline model defined by OpenFlow \cite{openflow_spec}.
Steve provides high-level language features for specifying
stages in this pipeline and how these stages connect.
Specifically, Steve allows for the definition of:

\textbf{Header Structures}.
A programmer may define the structure of any protocol header using an abstract
mechanism known as a \emph{layout}.
A layout specifies what fields are in a header, the lengths of those fields,
and types for those fields.

\textbf{Decoders}. Decoders are pipeline stages used to extract 
fields from a packet header. 
They conform to user-defined layouts, making them flexible enough
to deal with any protocol header.

%
% Steve allows the user to program special functions decoders
% which are used for decoding and extract fields from a header. Decoders allow
%the
% user to specify which fields they need. Decoders do not require that a user
% extract all fields if they do not need those fields. The user is not required
%to
% manually extract the bytes associated with a field. Instead, the user gives a
% field name from the header layout they defined, and the language generates the
% code for them.

\textbf{Flow tables}.
Flow tables are pipeline stages responsible for the majority of forwarding logic.
In networking, a \emph{flow} is a group of packets from a source to one 
or more  destinations. In order to facilitate these flows, Steve uses \emph{flow tables} (an OpenFlow inspired abstraction). 
A flow table is a dynamic
decision table which classifies packets into groups (flows) using
decision rules (known as \emph{flow entries}).
Packets which are part of the same flow have a common set of \emph{actions}
applied to them.

\textbf{Actions}. Actions provide a way to modify a packet's fields, add/remove
flow entries from tables, and forward/drop packets. Steve actions are a
generalization
of OpenFlow's instructions and actions.

\textbf{Pipeline Composition}. A Steve pipeline is a composition of two kinds of
stages: decoders and flow tables.
Steve provides languages features for describing how these stages are linked
together. It also provides safety guarantees on the pipeline.

\subsection{Event Handling and Control}

The pipeline may raise events to the control plane when
it cannot handle a packet. Steve allows for the definition of
\emph{event handlers} -- control plane functions which deal
with these special circumstances.
Unlike the pipeline, event handlers can execute a wider range of
operations that are too slow for a data plane such as:
logging, flow table modification, C library calls, etc.

\subsection{General Purpose Features}

Though Steve is an SDN language, it also supports a number of general purpose
features. 
Steve supports functions, variables, arithmetic, branching, 
looping and a foreign function interface which may be used to call linked C 
library functions.

\section{Contribution: A Language for Defining Safe Pipelines}

The Steve language provides a type and constraints system to ensure the safety
of all Steve-defined packet operations and pipelines.
In addition, Steve uses an optimizing compiler to ensure efficient code
generation
and a runtime environment to abstract hardware resources (ports, memory, etc).

\subsection{Type Safety}

Steve is a statically-typed language. The compiler performs additional work to
enforce strict safety guarantees so that runtime checks can be avoided as much
as possible.

The Steve type system ensures that operations on header fields are valid and
well-defined. 
To reduce errors related to working with fields as byte buffers, Steve allows
for the representation of fields as arbitrary precision, signed or unsigned
integers.
Implicit integer conversions can be applied to these fields where necessary.
Conversions prevent field modification from ever underflowing or overflowing.

%Steve does not support pointer types, meaning that the programmer is never
%concerned with null or invalid pointer addresses. Instead, Steve supports
%reference
%types which are guaranteed to refer to initialized memory.

%\begin{enumerate}
%\item the representation of fields as
%arbitrary precision, signed or unsigned integers, (as long as they
%are multiples of 8). This allows the programmer to avoid using arrays of bytes
%to represent fields.
%
%\item logical and arithmetic expressions which are type checked
%to ensure no undefined behavior happens (e.g. shifting by negative values,
%adding to a boolean, etc).
%
%\item implicit conversions can be applied where necessary (e.g. integer size
%promotion, unsigned to signed conversions, etc).
%
%\item buffer overflow/underflow prevention. 
%Writing a new value into a header field \textit{never} causes accidental
%buffer overflows. The Steve compiler uses implicit conversions to guarantee
%that
%the size of the new value fits exactly into the byte width of a field. If the
%new value is represented in less bytes than the size of field, it gets extended
%to fit. Values that are too large get truncated.
%\end{enumerate}


% Specifically, the Steve language aims to avoid:
%
% \begin{itemize}
% \item accessing memory outside the bounds of a packet buffer,
%
% \item writing bytes which exceed a contrained subset of the packet
% resulting in a buffer overflow (i.e. writing new bytes into a header field
% but exceeding the size of that field),
%
% \item buffer underflow resulting from not writing enough bytes when modifying
% a field,
%
% \item using the value of a field in an operation that is not supported by its
% range of value,
%
% \item non-terminating cycles of decoders and table matchings (an infinite loop
% of packet processing),
%
% \item incorrect assumptions about decoding state. That is, a programmer using
% a field which they have not extracted yet.
% \end{itemize}

\subsection{Pipeline Constraints System}

The Steve compiler ensures certain guarantees about the correctness of a Steve
pipeline. Steve pipelines may be represented as directed acyclic graphs. The
Steve compiler performs analysis on this graph to enforce the following
constraints.

\begin{enumerate}
\item Fields that have not been extracted by a decoder cannot be used. 

\item The traversal of a packet through a pipeline is always a linear
progression. That is, a packet may never enter a non-terminating cycle
of decoders and tables.
\end{enumerate}

\subsection{Resource Safety}

Steve never requires the user to heap allocate resources. The majority of
allocation is done on the stack, ensuring Steve applications are free of
memory leakage and faster (as heap allocation tends to be slow).

Steve relies on its runtime environment, Freeflow \cite{freeflow_software}, 
to manage system resources such as
ports, packet reading, and packet buffer allocations.
This decouples the logic of system resource management from the packet
processing logic.

\subsection{Efficiency}

%Steve's programmable decoders provide the user the chance at certain
%optimizations. Steve allows the user to specify exactly which fields from a
%header they want extracted rather than forcing them to extract the entire
%thing.

High-level abstractions tend to produce performance penalties in exchange
for safety. The Steve compiler tries to reduce this penalty as much as possible.
The Steve compiler generates LLVM intermediate representation (IR) code
\cite{llvm_webpage}. The LLVM IR optimizing compiler is able to produce 
code equivalent to C programs. It also provides benefits such as
function inlining, peephole optimizations, etc.

Steve may also customize the LLVM compiler to produce
specialized instructions that are optimized for the architecture running
the application. This would be future work.

\section{Contribution: Modules For Freeflow Switches}

In order to validate that our language abstractions work, the Steve compiler builds modules (dynamic link libraries (DLL))
loaded by the Freeflow virtual machine (FFVM). The compiler currently targets an x86 architecture,
but can be adapted to target other platforms as well.

Freeflow is a virtual machine (VM) that also serves as the Steve runtime
environment \cite{freeflow_software}.
FFVM abstracts underlying switch
hardware and services and exposes them through an interoperable ABI.
Freeflow is a VM in the similar sense that Java Virtual Machine (JVM) is a VM. Targeting the VM ABI allows high-level applications to avoid generating architecture dependent code and optimizations.

FFVM may also be considered a software data plane.
A Steve module is designed to program FFVM's data plane pipeline by providing
flow table configuration, flow table entries, and packet decoders.
The module also instantiates the control plane for FFVM with the appropriate
event handlers.

\section{Thesis Overview}

This thesis is organized as follows. Chapter \ref{ch:related} describes similar
works in the field of SDN and SDN programming languages. It also provides a
background into SDN and the different approaches Steve takes to other languages
of its kind.

Chapter \ref{ch:pipeline_model} describes the components of Steve abstract machine. It explains the abstract model for packet processing pipelines and event handling.

Chapter \ref{ch:tutorial} describes the Steve programming language and how it is used to writing network functions.
Sample networking applications are also presented in
this chapter. These same samples are presented again in Appendix
\ref{ap:steve_programs}.

Chapter \ref{ch:limits} elaborates on pipeline safety guarantees and how they are enforced
as well as providing the proofs. It also provides explanations about other 
limitations of the language and why they exist.

Appendix \ref{ch:users_guide} serves as a reference
manual which includes semantic, grammar, and typing rules for the language.
This reference manual may be helpful to refer to when confused about a
Steve code example.

Chapter \ref{ch:flowpath} describes the interface which must be exposed by the switch or software running the switch. To validate this approach, this chapter also summarizes Freeflow, a virtual data plane which exposes this interface to Steve \cite{freeflow_software}. It also describes the interface which a Steve application exposes to the switch.

Chapter \ref{ch:experiments} provides experiments using sample Steve
applications. Pcap files are run through Steve applications to measure the data
rate and raw packet rate that each application is capable of running at on a
Linux machine.

Chapter \ref{ch:conclusion} details future work for Steve and provides concluding remarks about the project.