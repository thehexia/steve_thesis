\chapter{INTRODUCTION} \label{ch:intro}

% FIXME: The introduction needs to flow. Don't break it up into this kind of
% question and answer dialog, and don't skimp on motivation. Take this guy's
% PhD thesis as an example:
%
% http://www.cs.colostate.edu/~christos/thesis/chp1.pdf
%
% It's a little more detailed than you'll need, but it's a good example of
% how to motivate the problem and organize both the solution and your
% contributions.

% FIXME: Use \emph to emphasize terms, not boldface.

The Internet is nowadays ubiquitous with everyday life. In the last twenty
years,
the industry has rapidly evolved to incorporate all kinds of new Internet
services:
cloud services, web services, Internet of Things, etc. As the world grows
more reliant on services provided over a network, so must the communication network evolve.

The backbone of all networks is the \emph{switch}. The term ``switch'' is used in this thesis to mean any device capable of making forwarding decisions across multiple layers of the OSI stack \cite{osi_model}. It thus incorporates bridges, routers, hardware firewalls, etc.
The problem is that modern switches suffer from a number of issues which make them difficult to use in an industry where networks are becoming increasingly elaborate.

Conventional switches are complex and unscalable because they are only designed to deal with very specific sets of well-known protocols and use cases. A router, for example, may be reconfigured with new forwarding rules, but it will never be anything other than a router. The behavior is difficult if not impossible to change, making these devices very rigid.
Because they may only be reconfigured within a limited use case, they cannot easily adapt to dynamic changes in network traffic and load.
Even when reconfiguring, network administrators are often forced to do so through clunky, vendor-imposed command line interfaces.

However, future networks will require that network flows be directed in increasingly complex ways. More protocols and information will be carried on packets than ever before, and the modern switch model is not flexible enough to handle it all.
In order to bypass this inflexibility, it must be possible to implement network functions (routing, firewalls, NAT, etc) through intelligent networking applications implemented in software.
These applications must be capable of automatically adapting to changing network conditions by modifying switch behavior to optimize forwarding decisions, throughput, resource consumption, etc.
There must also exist a switch which is capable of installing and running this software.

This is the promise of \emph{software-defined networking} (SDN).
SDN aims to make two elements of a conventional network switch programmable: the data plane and the control plane. The \emph{data plane}, sometimes called the \emph{forwarding plane}, is the element which is responsible for decoding packet content and deciding which port to forward to based on that content. The control plane manages the data plane. It is the element which learns and configures the forwarding logic used by the data plane. It is also capable of processing packets which are too complex or slow for the data plane.

The Open Network
Foundation (ONF) defines SDN as the ``separation of the network control
plane from the forwarding [data] plane'' \cite{onf_sdn_def}.
%Either of these components may then be implemented in regular software.
%The goal of SDN is to provide highly programmable, scalable, and
%efficient network switches.
The control plane is replaced by a software application known as a \emph{controller} (software control plane), which manages switch behavior.
It may be run on any machine, completely separate from its switch and data plane.
It may then perform distributed control over multiple data planes by communicating via network messages.
The most widely adopted standard for this communication is OpenFlow
\cite{openflow_spec}.
Because it may be run on any machine,
any programmer can write regular software for common operating
systems and processors to control the behavior of their networking device.

The \emph{programmable data plane} is implemented with specialized, programmable packet processors.
Software may then be installed to program this hardware.
A programmable data plane provides
a key benefit that the SDN controller cannot: \emph{protocol independence}.

%In the control and data plane relationship,
%the control plane is smart but slow, while the data plane is fast yet dumb.
%That is,
%the control plane can perform general purpose computing but communicating with
%it has high latency. The data plane, on the other hand, is the fast path for
%packet processing.
%It has very limited computing power, but can process packets at a low latency.
%As programmable data planes evolve and support more flexible instruction sets,
%communicating with the control plane becomes less necessary.

%The software control plane supports general purpose computing using heavyweight
%processors. However, general purpose computing is slow and communicating
%with the control plane over a network using messages is even slower.
%Data planes, on the other hand, can process packets incredibly fast since
%they are designed for this single role, but do not necessarily support
%the full range of general purpose operations.
%If data planes could support more kinds of computation, then they can rely less
%on
%slow control planes, and delegate only under the more extreme circumstances.

Protocol independence means that a networking device is not required, by default, to support
a suite of well-known protocols (Ethernet, IPv4, TCP, etc).
Rather than relying on specialized hardware or firmware tailored towards
parsing/decoding
these protocol headers, the data plane supports processors
and generic instructions that can be used operate on
any header and field.
This allows users to support any future protocol headers in addition to
supporting current, well-known ones. This makes the data plane scalable, that is, it
can adapt to new headers easily.

Because the programmable data plane can flexibly deal with any field, the programmer can change the behavior of the network switch without changing its hardware. One day it could be a bridge and the next it could be a firewall depending on the installed software.

%Intelligence implies that a machine or program is capable of performing a myriad of general purpose computations which one might find on normal CPU.
%Consider a router for example. These machines are said to be intelligent because of the algorithms they use to route traffic across multiple networks. They may even support intelligent load and content balancing. But are they really intelligent compared to what modern computers are capable of?
%
%Of course not. Modern devices use specialized hardware to process network traffic at maximum speeds, but as a trade-off, they lose the ability to perform general purpose computation that would support implementing intelligent network functions. Why is this so important?
%
%Network traffic can carry data which is completely inaccessible to many modern switches because they are incapable of processing everything. Consider how powerful it would be if any application could be installed on a network switch.




%Modern routers and switches provide the backbone for the Internet.
%These modern devices implement two fundamental components in their firmware: the
%\emph{data plane} and the \emph{control plane}. A control plane can be thought of as the brains of a network device, whereas the
%data plane is the brawn.
%
%The data plane is responsible for processing packet content and and moving them across the right ports.
%It makes fast forwarding decisions by using lookup tables to determine
%where a packet is sent. When it does
%not know how to handle a packet, it sends it to the control plane.
%
%A control plane manages its data plane.
%It is responsible for installing forwarding logic for a network device and is
%capable of learning new forwarding behaviors in response to unexpected packets.
%It does this by modifying the lookup tables used by the data plane.
%Together, the control and data plane implement \emph{network functions}, i.e.
%switching, NAT, firewall, etc.
%
%This model continues to be the most popular for switch development.
%However,
%this conventional type of networking has become too rigid, unscalable, and
%proprietary to support evolving technologies.
%
%Defining network functionality in firmware is inherently inflexible.
%Firmware is architecture-dependent, difficult to write, and challenging to
%update
%regularly.
%Conventional switches are unscalable because they must deal with most or all
%common protocol headers.
%With dozens of common protocols now, and potentially dozens more in the future,
%it becomes evident that this model cannot last forever.
%Additionally, many devices are black boxes,
%only exposing an interface designed by the vendor,
%making them difficult to customize for enterprises with special needs.
%By extension, these black box devices force any network functions
%defined over them to be extremely architecture dependent.
%Due to these issues and others, a new paradigm for networking was created.
%
%This new paradigm
%is called \textit{software-defined networking} (SDN).

\section{Motivation: A Specialized Language for Programming SDN Switches}

Some attempt to program SDN switches using C.
Others attempt to produce domain-specific languages (DSLs) for SDN devices.
The focus of this thesis is one such DSL, \emph{Steve}, a language for the specification of programs that perform packet processing and network flow direction 
for programmable SDN switches. 
Steve is tailored towards expressing network applications, and therefore provides high-level language abstractions for packet processing logic.
Additionally, Steve ensures a network application is safe, while still being as efficient as possible.

A network application must be safe to execute more than anything else.
Network applications, especially those running on high-traffic devices, must not
crash due to logical mistakes or unnoticed undefined behaviors.
At best, this produces expensive network downtime; at worst, this
opens the way for security vulnerabilities on the device:
denial of service attacks, buffer overflows, etc.

Unfortunately, programming network devices in C can be prone
to errors stemming from buffer and resource management, or logical mistakes made by the programmer. These errors can introduce vulnerabilities or impact performance.
These issues are compounded by the fact C is a general
purpose language not tailored towards expressing packet processing, thus the burden of
safety
is left to the programmer, with no compiler to double check their work.
Specifically, C programs risks errors such as:

\begin{itemize}
\item accessing memory outside the bounds of a packet buffer or outside a
constrained
region of memory,

\item writing bytes which exceed a constrained subset of the packet
resulting in a buffer overflow (i.e. writing new bytes into a header field
but exceeding the size of that field),

\item not writing enough bytes while modifying a field,

\item using a field in an operation that is not supported by its
range of values,

\item non-terminating cycles in program logic (infinite loops
triggered by a single packet),

\item incorrect assumptions about decoding state. That is, a programmer using
a field which they have not extracted yet or that does not exist.
\end{itemize}

Programmers using C for SDN applications are also burdened with management of
device resources. Specifically, a C programmer must manage:

\begin{itemize}
\item memory. The programmer must manage their own buffers for holding packet
data and packet meta data. This opens the opportunity for accidental
memory leakage.

\item ports. The programmer is responsible for receiving, reading, and
forwarding
through ports. This process should be decoupled from the packet processing logic
for modularity. Packet processing logic should be architecture
independent
whereas port management is a architecture dependent problem.

\item vendor optimizations. Having a specialized SDN language allows the compiler to map high-level abstractions down to specific architectures and vendor provided libraries.
\end{itemize}

% Low-level packet processing code can be very light on easy to understand
% abstraction and very heavy on gritty implementation details. The programmer
% should be focusing on high-level abstractions; concepts such as: what fields
%are
% needed, what operations must be performed on these fields, conditional
%decision
% making, packet classification, etc. Instead, they are worried about the many
% common ailments of writing in low-level code.
%
% The programmer must deal with resource allocation and management. They must
%deal
% with allocating their own buffers for storing packets and by extension must
%deal
% with de-allocating those buffers. This type of resource management is prone to
% accidental memory leakage, especially in C. Memory leakage of gigabytes of
%data
% will quickly bring a system down.
%
% The programmer must directly manage ports. They are also responsible for
% manually receiving, reading, and sending packets on those ports. This is code
%is
% common to all packet processing applications. The programmer should not be
% burdened with this kind of common code when writing a packet processor.
%
% When working with packet headers, the programmer must manually work with raw
% arrays of bytes. The burden of decoding fields from byte arrays and
%interpreting
% the value of those fields is shifted onto the programmer. Manual decoding can
%be
% a painful process on its own. It is prone to error, particularly off-by-N
% errors. When reinterpreting those bytes into header data structures, the
%result
% can be disastrous if the bytes are wrong or the data structure is wrong.
%Moving
% or copying those bytes around is particularly prone to buffer overflows.
%
% A number of other common problems come up when working in low-level code.
% Undefined behavior from reading past the end of packet buffers can be one.
% Performing operations on null pointers, invalid pointers, or uninitialized
% memory is another.
%
% Steve and its runtime, Flowpath, attempt to remedy most of these problems. The
% objective is to abstract many of these low-level details. Instead, the
% programmer only focuses on the high-level abstractions. Specifically, the
%Steve
% language focuses the programmer on writing the packet processing pipeline and
% makes the grittier details opaque


Steve focuses on the language features required for programming a single device. There must be a well-designed abstract machine for programming network applications on one switch before expanding to incorporate distributed control.

There are flaws in distributed control that a single device does not have to deal with.
Specifically, distributed control is slow.
The switch has to send messages over a network, the controller must process the message, then send more messages back to modify switch behavior. This latency is unnecessary for simple network functions.
The trade-off is that it allows for control over an
entire network.

A non-distributed control plane, on the other hand, has much
better performance.
It can exist on the
same hardware as the data plane and has little communication latency
because the two elements may communicate directly through an application
binary interface (ABI) -- symbols and calling conventions defining communication between the two elements.
This model is considerably more effective for simple network functions.
The programming model for a control and data plane on the same device
is basic event-driven programming (EDP).

The data plane raises events when it needs something from the control plane.
The control plane catches these events with special handlers and modifies the
forwarding logic accordingly.
A free benefit of this model is that a single language like Steve may
be used to define both control and data plane elements for a given
device.

\section{Contribution: The Steve Programming Language}

The Steve programming language was designed to solve the problem of safe and efficient programming of SDN devices.
Steve is used for writing applications that define packet processing and network flow direction on SDN devices.
It is protocol independent, strongly-typed,
and declarative.

This thesis provides Steve language features 
for defining \emph{packet
processing pipelines}, the core component used by a data plane
to process packet content and make forwarding decisions.
It also provides features for defining \emph{event handlers} --
control plane functions which process unexpected packets and
modify the data plane when necessary.

\subsection{Language Features}

The packet processing pipeline is a data plane algorithm that
uses multiple, smaller processing stages to decode packet content and make
forwarding decisions.
The Steve pipeline is a generalization
of the pipeline model defined by OpenFlow \cite{openflow_spec}.
Steve provides high-level language features for specifying
stages in this pipeline and how these stages connect.
Specifically, this thesis describes the following contributions towards language features:

\textbf{Header Structures}.
A programmer may define the structure of any protocol header using an abstract
mechanism known as a \emph{layout}.
A layout specifies what fields are in a header, the lengths of those fields,
and types for those fields.

\textbf{Decoders}. Decoders are pipeline stages used to extract
fields from a packet header.
They conform to user-defined layouts, making them flexible enough
to handle any protocol header.

%
% Steve allows the user to program special functions decoders
% which are used for decoding and extract fields from a header. Decoders allow
%the
% user to specify which fields they need. Decoders do not require that a user
% extract all fields if they do not need those fields. The user is not required
%to
% manually extract the bytes associated with a field. Instead, the user gives a
% field name from the header layout they defined, and the language generates the
% code for them.

\textbf{Flow tables}.
Flow tables are pipeline stages responsible for the majority of forwarding logic.
A \emph{flow} is a group of packets from a source to one
or more  destinations. In order to direct these flows, Steve uses \emph{flow tables} (an OpenFlow inspired abstraction).
A flow table is a dynamic
decision table which classifies packets into groups (flows) using
decision rules (known as \emph{flow entries}).
Packets which are part of the same flow have a common set of \emph{actions}
applied to them.

\textbf{Actions}. Actions provide a way to modify a packet's fields, add/remove
flow entries from tables, and forward/drop packets. Steve actions are a
generalization
of OpenFlow's instructions and actions.

\textbf{Pipeline Composition}. A Steve pipeline is a composition of two kinds of
stages: decoders and flow tables.
Steve provides languages features for describing how these stages are linked
together. It also provides safety guarantees on the pipeline.

\textbf{Event Handlers}.
The pipeline may raise events to the control plane when
it cannot handle a packet. Steve allows for the definition of
\emph{event handlers} -- control plane functions which deal
with these special circumstances.
Unlike the pipeline, event handlers can execute a wider range of
operations that are too slow or complex for a data plane such as:
logging, flow table modification, C library calls, etc.

%\subsection{General Purpose Features}
%
%Though Steve is an SDN language, it also supports a number of general purpose
%features.
%Steve supports functions, variables, arithmetic, branching,
%looping and a foreign function interface which may be used to call linked C
%library functions.

\subsection{Language Safety}
%
%The Steve language provides a type and constraints system to ensure the safety
%of all Steve-defined packet operations and pipelines.
%In addition, Steve uses an optimizing compiler to ensure efficient code
%generation
%and a runtime environment to abstract hardware resources (ports, memory, etc).
%
%\subsection{Type Safety}

This thesis also describes solutions for ensuring language safety.
Steve is a statically-typed language. The compiler performs additional work to
enforce strict safety guarantees so that runtime checks can be avoided as much
as possible.

The Steve type system ensures that operations on header fields are valid and
well-defined.
To reduce errors related to working with fields as byte buffers, Steve allows
for the representation of fields as fixed-width, signed or unsigned
integers.
Implicit integer conversions can be applied to these fields to ensure that the correct number of bytes is always being written into the packet, making buffer overflows impossible.
Additionally, Steve's layouts prevent the programmer from making common mistakes while extracting fields or manipulating protocol headers.

%Steve does not support pointer types, meaning that the programmer is never
%concerned with null or invalid pointer addresses. Instead, Steve supports
%reference
%types which are guaranteed to refer to initialized memory.

%\begin{enumerate}
%\item the representation of fields as
%arbitrary precision, signed or unsigned integers, (as long as they
%are multiples of 8). This allows the programmer to avoid using arrays of bytes
%to represent fields.
%
%\item logical and arithmetic expressions which are type checked
%to ensure no undefined behavior happens (e.g. shifting by negative values,
%adding to a boolean, etc).
%
%\item implicit conversions can be applied where necessary (e.g. integer size
%promotion, unsigned to signed conversions, etc).
%
%\item buffer overflow/underflow prevention.
%Writing a new value into a header field \textit{never} causes accidental
%buffer overflows. The Steve compiler uses implicit conversions to guarantee
%that
%the size of the new value fits exactly into the byte width of a field. If the
%new value is represented in less bytes than the size of field, it gets extended
%to fit. Values that are too large get truncated.
%\end{enumerate}


% Specifically, the Steve language aims to avoid:
%
% \begin{itemize}
% \item accessing memory outside the bounds of a packet buffer,
%
% \item writing bytes which exceed a contrained subset of the packet
% resulting in a buffer overflow (i.e. writing new bytes into a header field
% but exceeding the size of that field),
%
% \item buffer underflow resulting from not writing enough bytes when modifying
% a field,
%
% \item using the value of a field in an operation that is not supported by its
% range of value,
%
% \item non-terminating cycles of decoders and table matchings (an infinite loop
% of packet processing),
%
% \item incorrect assumptions about decoding state. That is, a programmer using
% a field which they have not extracted yet.
% \end{itemize}

%\subsection{Pipeline Constraints System}

The Steve compiler ensures certain guarantees about the correctness of a Steve
pipeline through a specialized constraints system. Steve pipelines may be represented as directed graphs. The
Steve compiler performs analysis on this graph to enforce the following
constraints.

\begin{enumerate}
\item Fields that have not been extracted by a decoder cannot be used.

\item The traversal of a packet through a pipeline is always a forward
progression. That is, a packet may never enter a non-terminating cycle
of decoders and tables.
\end{enumerate}

Additionally, Steve is resource safe, that is, it 
never requires the user to heap allocate resources or manage device resources. 
All memory allocation in Steve is done on the stack, ensuring Steve applications are free of
memory leakage and faster.

Steve relies on its runtime environment, Freeflow \cite{freeflow_software},
to manage system resources such as
ports, packet reading, and packet buffer allocations.
This decouples the logic of system resource management from the packet
processing logic.

\subsection{Compiler}

%Steve's programmable decoders provide the user the chance at certain
%optimizations. Steve allows the user to specify exactly which fields from a
%header they want extracted rather than forcing them to extract the entire
%thing.

The Steve compiler implements these safety guarantees as well as ensuring efficient code generation for network applications.
It generates LLVM intermediate representation (IR) code
\cite{llvm_webpage} from Steve syntax. LLVM was chosen because it is architecture-independent, extensible, and well-supported.
The LLVM IR optimizing compiler is used to optimize Steve code as much as possible.
The LLVM compiler infrastructure can also be modified to support special intrinsics which can be optimized for specific switch architectures.
Right now, it targets an x86 architecture.

%Steve may also customize the LLVM compiler to produce
%specialized instructions that are optimized for the architecture running
%the application. This would be future work.

%\section{Contribution: Modules For Freeflow Switches}

In order to validate that our language abstractions work, the Steve compiler builds modules (dynamic link libraries)
loaded by the Freeflow virtual machine (FFVM).
FFVM is a software data plane which also provides the Steve runtime environment \cite{freeflow_software}.
FFVM abstracts underlying switch
hardware and services and exposes them through an interoperable ABI which may be called by the Steve application.
%Freeflow is a VM in the similar sense that Java Virtual Machine (JVM) is a VM. Targeting the VM ABI allows high-level applications to avoid generating architecture dependent code and optimizations.
A Steve module provides the FFVM's packet processing pipeline with
flow table configuration, flow table entries, and packet decoders.
The module also acts as the controller for FFVM's data plane and therefore provides an event handler interface which the data plane can call when it needs the control plane to process a packet.

\section{Thesis Overview}

This thesis is organized as follows. Chapter \ref{ch:related} describes similar
works in the field of SDN and SDN programming languages. It also provides a
background into SDN and the different approaches Steve takes to other languages
of its kind.

Chapter \ref{ch:pipeline_model} describes the Steve architecture and abstract machine. It explains the abstract model for packet processing pipelines and event handling.

Chapter \ref{ch:examples} demonstrates how to use Steve to write some simple network applications.
These same samples are presented again in Appendix
\ref{ap:steve_programs}.
Chapter \ref{ch:tutorial} describes all of the language features contributed by this thesis and their use cases.

Chapter \ref{ch:limits} elaborates on pipeline safety guarantees, what algorithms enforce them, and the proofs for these algorithms. It also provides explanations about other
limitations of the language and why they exist.

Chapter \ref{ch:flowpath} describes the interface which must be exposed by the switch for Steve applications to run. To validate this approach, this chapter also summarizes Freeflow, a virtual data plane which exposes this interface to Steve \cite{freeflow_software}. It also describes the interface which a Steve application exposes to the switch.

Chapter \ref{ch:experiments} provides experiments using sample Steve
applications. Packet capture (pcap) files are run through Steve applications to measure the performance of applications on a Linux machine.
Chapter \ref{ch:conclusion} provides discussion, details future work for Steve, and provides concluding remarks about the project.

Appendix \ref{ch:users_guide} serves as a reference
manual which includes semantic, grammar, and typing rules for the language. References to this appendix are made throughout this thesis as needed.
