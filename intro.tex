\chapter{INTRODUCTION} \label{ch:intro}

% FIXME: The introduction needs to flow. Don't break it up into this kind of
% question and answer dialog, and don't skimp on motivation. Take this guy's
% PhD thesis as an example:
%
% http://www.cs.colostate.edu/~christos/thesis/chp1.pdf
%
% It's a little more detailed than you'll need, but it's a good example of
% how to motivate the problem and organize both the solution and your
% contributions.

% FIXME: Use \emph to emphasize terms, not boldface.

% FIXME: Use this sentence in your abstract.

The Internet is nowadays ubiquitous with everyday life. In the last twenty years,
the industry has rapidly evolved to incorporate all kinds of new Internet services:
cloud services, web services, Internet of Things, etc. As the world grows more and
more reliant on services provided over a network, so must the network evolve.

Modern routers and switches provide the backbone for the Internet.
These modern devices implement two fundamental components in their firmware: the
\emph{control plane} and the \emph{data plane}.
The control plane decides where packets should be sent and is capable of learning
new forwarding behaviors. The control plane commands the data plane.
The data plane is responsible for moving packets between ports.

Over time this conventional type of networking became rigid, unscalable, and
proprietary. Defining network functionality in firmware is inherently inflexible.
Firmware is architecture-dependent, difficult to write, and challenging to update
regularly.
Conventional switches are unscalable because they must deal with most or all
common protocol headers.
With dozens of common protocols now, and potentially dozens more in the future,
it becomes evident that this model cannot last forever.
Additionally, many devices are black boxes,
only exposing an interface exposed by the vendor,
making them difficult to customize for enterprises with special needs.

Due to these and others,
a new paradigm for networking was created. This new paradigm
is called \textit{software-defined networking} (SDN). The Open Network
Foundation (ONF) defines SDN as ``the physical separation of the network control
plane from the forwarding [data] plane'' \cite{onf_sdn_def}.
The control plane is removed from the firmware.
Instead, it is implemented in software.
This software control plane is capable of controlling several devices over a
single network using messages. Much of the work into SDN has targeted OpenFlow
\cite{openflow_spec}, an open-source standard for SDN switches. The benefit of
these switches is that any programmer can write regular software on typical operating
systems to control the behavior of their networking device.

The programmable control plane is only the first step. The next
step is the \emph{programmable data plane}. A programmable data plane provides
two key benefits: \emph{protocol independence} and low-latency, customized packet
processing.

Protocol independence means that a networking device is not reliant on supporting
a suite of well-known protocols (ethernet, IPv4, TCP, etc).
Rather than relying on specialized hardware or firmware tailored towards parsing/decoding
these protocols, the data plane supports processors
and generic instructions that a user could use to decode and operate on
any header and field.
This allows users to define their own protocols in addition to
supporting well-known protocols. This makes the data plane scalable, that is, it
can adapt to new headers easily.

In the control and data plane relationship,
the control plane is smart but slow, while the data plane is fast yet dumb. That is,
the control plane can perform general purpose computing but communicating with
it has high latency. The data plane, on the other hand, is the fast path for packet processing.
It has very limited computing power, but can process packets at a low latency.
As programmable data planes start to support more general purpose operations,
the communicating with the control plane becomes less necessary, and data planes
grow more flexible.

In order to pursue programmable SDN devices, there must be a language to write
packet processing program. A number of language solutions arise here.
Some attempt to solve this problem by providing APIs for existing programming languages
(specifically C/C++).
Others attempt to produce domain-specific languages (DSLs) for SDN devices.

The focus of this thesis is one such DSL, Steve, a language for the safe and
efficient specification of packet processing applications for programmable data
and control planes.

% Packet processing and forwarding logic is usually performed using an abstract
% model known as a \emph{packet processing pipeline} which is a generalization of
% the pipeline model described by OpenFlow \cite{openflow_spec}.


%
% The programmer can customize a switch with customized packet processing
% applications and forwarding rules. Typically, this is done through an abstract
% model called a \textit{packet processing pipeline}.
% The pipeline makes decisions, performs operations, and applies forwarding rules on packets.
%
% Forwarding rules can handle any header and can be user-defined. It opens the way
% to networking applications made for custom protocols and forwarding behaviors.
% By changing the program which drives the packet processing pipeline, the user
% can \textit{change the device's behavior without changing the device's
% hardware}. The same device can go from being a repeating hub to a MAC learning
% switch to a router just by running a different program on it.

\section{The Steve Programming Language}

The Steve programming language is a protocol independent, architecture indepedent,
declarative language for packet processing on SDN devices.
Steve defines network functions using an abstract model
known as a \emph{packet processing pipeline} -- a model which is a generalization
of the pipeline defined by OpenFlow \cite{openflow_spec}.
A packet processing pipeline is an algorithm which
uses multiple stages to process and forward packets.
Steve provides high-level language features for specifying stages in this pipeline.
To support the definition of these pipelines, Steve provides language features
for:

\textbf{Header Structures}.
A programmer may define the structure of any protocol header using an abstract
mechanism known as a \emph{layout}.
A layout specifies what fields are in a header, the lengths of those fields,
and types for those fields.

\textbf{Decoders}. Decoders are special functions for extracting fields from a
packet header. They conform to user-defined layouts, making them flexible enough
to deal with any protocol header.

%
% Steve allows the user to program special functions decoders
% which are used for decoding and extract fields from a header. Decoders allow the
% user to specify which fields they need. Decoders do not require that a user
% extract all fields if they do not need those fields. The user is not required to
% manually extract the bytes associated with a field. Instead, the user gives a
% field name from the header layout they defined, and the language generates the
% code for them.

\textbf{Flow tables}. A flow table (an OpenFlow inspired abstraction) is a dynamic
decision table which classifies packets into groups (known as \emph{flows}) using
decision rules (known as \emph{flow entries}).
Packets which are part of the same flow have a common set of \emph{actions}
applied to them.
Flow tables are responsible for the majority of forwarding logic.

\textbf{Actions}. Actions provide a way to modify a packet's fields, add/remove
flows from tables, and forward/drop packets. Steve actions are a generalization
of OpenFlow's instructions and actions.

\textbf{Pipeline Composition}. A Steve pipeline is a composition of two stages:
decoders and flow tables.
A packet moves through these stages which perform some set of processing operations.
Eventually one of these stages will make a forwarding decision for that packet.
The language provides a mechanism for connecting these
stages together in a number of flexible ways.

\section{Why Steve? -- Issues with Other Languages}

A network program must enforce safety over any other concepts.
Network programs, especially those running on high-traffic devices, must not
crash due to logical mistakes or unnoticed undefined behaviors.
Such errors could result in security holes, denial of service attacks, and
disastrous network downtime.

Typical packet processing programs are written in low-level languages, most
commonly C. These C programs usually work with data plane programming APIs such
as Open Data Plane (ODP) \cite{odp_webpage} and the Data Plane Programming Kit
(DPDK) \cite{dpdk_webpage}. Programming network functions in C can be prone
to logical error and unnoticed undefined behavior stemming from buffer management
and resource management. These issues are compounded by the fact C is a general
purpose language not tailors toward packet processing, thus the burden of safety
is left to the programmer.
Specifically, C programs open the opportunity for logical errors and undefined
behaviors such as:

\begin{itemize}
\item accessing memory outside the bounds of a packet buffer,

\item writing bytes which exceed a contrained subset of the packet
resulting in a buffer overflow (i.e. writing new bytes into a header field
but exceeding the size of that field),

\item buffer underflow resulting from not writing enough bytes when modifying
a field,

\item using the value of a field in an operation that is not supported by its
range of value,

\item non-terminating cycles in program logic (an infinite loop
triggered by a single packet),

\item incorrect assumptions about decoding state. That is, a programmer using
a field which they have not extracted yet.
\end{itemize}

Programmers using C for SDN applications are also burdened with management of
device resources. Specifically, a C programmer must manage:

\begin{itemize}
\item memory. The programmer must manage their own buffers for holding packet
data and packet meta data. This opens the opportunity for accidental
memory leakage.

\item ports. The programmer is responsible for receiving, reading, and forwarding
through ports. This process should be decoupled from the packet processing logic
for flexibility. A packet processing application should be architecture independent
whereas port management is a very architecture dependent thing.
\end{itemize}

% Low-level packet processing code can be very light on easy to understand
% abstraction and very heavy on gritty implementation details. The programmer
% should be focusing on high-level abstractions; concepts such as: what fields are
% needed, what operations must be performed on these fields, conditional decision
% making, packet classification, etc. Instead, they are worried about the many
% common ailments of writing in low-level code.
%
% The programmer must deal with resource allocation and management. They must deal
% with allocating their own buffers for storing packets and by extension must deal
% with de-allocating those buffers. This type of resource management is prone to
% accidental memory leakage, especially in C. Memory leakage of gigabytes of data
% will quickly bring a system down.
%
% The programmer must directly manage ports. They are also responsible for
% manually receiving, reading, and sending packets on those ports. This is code is
% common to all packet processing applications. The programmer should not be
% burdened with this kind of common code when writing a packet processor.
%
% When working with packet headers, the programmer must manually work with raw
% arrays of bytes. The burden of decoding fields from byte arrays and interpreting
% the value of those fields is shifted onto the programmer. Manual decoding can be
% a painful process on its own. It is prone to error, particularly off-by-N
% errors. When reinterpreting those bytes into header data structures, the result
% can be disastrous if the bytes are wrong or the data structure is wrong. Moving
% or copying those bytes around is particularly prone to buffer overflows.
%
% A number of other common problems come up when working in low-level code.
% Undefined behavior from reading past the end of packet buffers can be one.
% Performing operations on null pointers, invalid pointers, or uninitialized
% memory is another.
%
% Steve and its runtime, Flowpath, attempt to remedy most of these problems. The
% objective is to abstract many of these low-level details. Instead, the
% programmer only focuses on the high-level abstractions. Specifically, the Steve
% language focuses the programmer on writing the packet processing pipeline and
% makes the grittier details opaque.

\section{Contribution: A Language for Defining Safe Pipelines}

The Steve language provides a type and constraints system to ensure the safety
of all Steve-defined pipelines.
Steve targets the runtime environment, Flowpath, which abstracts resource management,
such as memory and ports, of a given hardware device.
In addition, Steve uses an optimizing compiler to ensure efficient code generation.

\subsection{Type Safety}

Steve is a statically-typed language. Steve prevents the user from using header
fields in ways that would result in obvious bugs or crashes. Steve supports:

\begin{enumerate}
\item the representation of fields as
arbitrary precision, signed or unsigned integers, (as long as they
are multiples of 8). This allows the programmer to avoid using arrays of bytes
to represent fields.

\item logical and arithmetic expressions which are type checked
to ensure no undefined behavior happens (e.g. shifting by negative values,
adding to a boolean, etc).

\item implicit conversions can be applied where necessary (e.g. integer size
promotion, unsigned to signed conversions, etc).

\item buffer overflow/underflow prevention. 
Writing a new value into a header field \textit{never} causes accidental
buffer overflows. The Steve compiler uses implicit conversions to guarantee that
the size of the new value fits exactly into the byte width of a field. If the
new value is represented in less bytes than the size of field, it gets extended
to fit. Values that are too large get truncated.
\end{enumerate}


% Specifically, the Steve language aims to avoid:
%
% \begin{itemize}
% \item accessing memory outside the bounds of a packet buffer,
%
% \item writing bytes which exceed a contrained subset of the packet
% resulting in a buffer overflow (i.e. writing new bytes into a header field
% but exceeding the size of that field),
%
% \item buffer underflow resulting from not writing enough bytes when modifying
% a field,
%
% \item using the value of a field in an operation that is not supported by its
% range of value,
%
% \item non-terminating cycles of decoders and table matchings (an infinite loop
% of packet processing),
%
% \item incorrect assumptions about decoding state. That is, a programmer using
% a field which they have not extracted yet.
% \end{itemize}

\subsection{Pipeline Guarantees}

The Steve compiler ensures certain guarantees about the correctness of a Steve
pipeline. Steve pipelines may be represented as directed acyclic graphs. The
Steve compiler performs analysis on this graph to enforce the following
constraints.

\begin{enumerate}
\item Fields that have not been extracted by a decoder cannot be used. It is
possible for a programmer to have forgotten to decode a field before using its
value later in the pipeline. Each stage explicitly states which fields it needs.
The Steve compiler traverses all possible paths through a pipeline to confirm
that a used field has been decoded at least once in the current or prior stage.

\item The traversal of a packet through a pipeline is always a linear
progression. The packet must always move from exactly one stage in the pipeline
to exactly one other stage. That packet may \textit{not} return to a stage it
has already visited. This property ensures that a packet can never infinitely
loop through stages in a pipeline.
\end{enumerate}




% \section{Contributions: A Language for Safe Packet Processing Pipelines}
%
% Steve is a high-level SDN language for defining protocol oblivious packet
% processing pipelines for programmable data planes. Steve's packet processing
% pipelines are programs which provide packet decoding, manipulation, and
% forwarding functionalities. The language is easy to write and comprehend for new
% users. Most importantly it ensures type safety, efficiency, resource safety, and
% certain logical guarantees on all user-written pipelines.
%
% \subsection{Language Features}
%
% Steve language features allow a programmer to express the high level
% abstractions needed for writing packet processing pipelines.









\subsection{Resource Safety}

Steve is resource safe, that is, the user is \emph{never} required to allocate
or de-allocate their own memory. The lifetime and storage duration of all memory
is \textit{automatic}. That is, memory is allocated and maintained by the
Flowpath runtime environment. It is almost impossible to produce a memory leak
in Steve.

Steve does not support pointer types so the user is never concerned with null
pointers. Steve does support reference types, which must always refer to valid
memory. This prevents the user from ever using invalid memory.

The Flowpath runtime environment manages all ports. The user does not concern
themselves with the details of how packets are received, copied, or sent. They
only concern themselves with describing how those packets are processed and
where those packets get forwarded.

\subsection{Efficiency}

Steve's programmable decoders provide the user the chance at certain
optimizations. Steve allows the user to specify exactly which fields from a
header they want extracted rather than forcing them to extract the entire thing.


The Steve compiler generates LLVM intermediate representation (IR) code
\cite{llvm_webpage}, which is the same IR used by the Clang compiler
\cite{clang_webpage}. The IR is then compiled into assembly code using the LLVM
compiler. This allows Steve programs to gain the benefits of an optimizing
compiler. This includes function inlining, peephole optimizations, etc.

\subsection{Flowpath Runtime Environment}

Flowpath is a runtime environment and a programmable software data plane. The
Steve programming language compiles into dynamic link libraries, known as
\emph{Steve applications}, which the Flowpath runtime can load and execute. A
Steve application provides the packet decoding functionality, configures the
flow tables on the data plane, and manages control flow through pipeline stages.

\section{Thesis Overview}

This thesis is organized as follows. Chapter \ref{ch:related} describes similar
works in the field of SDN and SDN programming languages.

Chapter \ref{ch:pipeline_model} describes the abstract switch model used by
Flowpath and the abstract pipeline process model in detail. Cahpter
\ref{ch:flowpath} describes how the Steve and Flowpath runtime environment
interact.

Chapter \ref{ch:tutorial} explains how to write network applications using the
Steve programming language. Sample networking applications are also presented in
this chapter. These same samples are presented again in Appendix
\ref{ap:steve_programs}. Chapter \ref{ch:users_guide} serves as a reference
manual which includes semantic, grammar, and typing rules for the language.

Chapter \ref{ch:experiments} provides experiments using the sample Steve
applications. Pcap files are run through Steve applications to measure the data
rate and raw packet rate that each application is capable of running at on a
Linux machine.
