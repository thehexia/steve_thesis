\chapter{INTRODUCTION} \label{ch:intro}

% FIXME: The introduction needs to flow. Don't break it up into this kind of
% question and answer dialog, and don't skimp on motivation. Take this guy's
% PhD thesis as an example:
%
% http://www.cs.colostate.edu/~christos/thesis/chp1.pdf
%
% It's a little more detailed than you'll need, but it's a good example of
% how to motivate the problem and organize both the solution and your
% contributions.

% FIXME: Use \emph to emphasize terms, not boldface.

% FIXME: Use this sentence in your abstract.


Packet-switched networks have gone through an explosive evolution over the last half century. In the late 1960's, there was ARPANET which connected a sparse few computers across the global using the early TCP/IP protocols. By the late 1980's, networks were becoming more and more accessible with the first Internet service providers starting up. As the 1990's began ARPANET was retired, but the new, modern Internet had arisen to take its place. Through the 1990's and early 2000's new application protocols were produced which allowed for emails, instant messaging, voice communication, videos, and so forth to be sent over networks. 

The Internet, which is nowadays ubiquitous with everyday life, connecting millions of computers across the globe, continues to drive networking technology forward. The network hardware used to connect computers has evolved. Primitive wires and repeater hubs evolved into more intelligent devices. 

These intelligent devices such as MAC switches and IP routers relied on the expanded firmware which gave them their functionality. These devices implemented two fundamental components, the control plane and the data plane, within their firmware.

The control plane is the device's ``brain.'' It decides where packets should be sent and is capable of learning new forwarding behaviors over time. The control plane commands the data plane. The data plane is the device's ``brawn.'' It actually moves the packets from port to port. Almost all modern networking devices continue to operate using this conventional model.  

The firmware for these devices, are rarely ever updated. On some devices, changes may not even be possible. Even if a device is updated, its overall behavior rarely changes. These devices are dedicated to one singular task for the duration of their lifetime. This type of networking device is known as \emph{hardware defined networking}.

Over time this conventional type of networking is complex, rigid, and proprietary. These devices are built to handle an absurd amount of protocols. These protocols, however, can rarely evolve because devices cannot handle unexpected new protocols. Their behavior cannot be easily customized or changed. Developers of these devices do not expose interfaces to the internals of the system. These all impede businesses who rely on these devices to offer services of the Internet.

Due to these issues, a new paradigm for networking appeared. This new paradigm is called \textit{software-defined networking} (SDN). The Open Network Foundation (ONF) defines SDN as ``the physical separation of the network control plane from the forwarding plane, and where a control plane controls several devices \cite{onf_sdn_def}. In essence, the control plane is removed from the firmware. Instead, it is implemented in software. This software control plane is capable of controlling several devices over a single network using messages. The most commonly used standard for this SDN architecture is OpenFlow \cite{openflow_spec}.

With open-source SDN, any programmer can write regular software on typical operating systems to customize the behavior of their networking device. No special training for proprietary devices is required.

However, the programmable control plane is only the \emph{first step}. The next step is the \emph{programmable data plane}. This type of SDN architecture attempts to make the data plane arbitrarily programmable as well. What benefits does this have?

The ability to program the packet processing functionality is one advantage. Rather than relying on specialized hardware or firmware tailored towards decoding a massive suite of well-known protocol headers, the data plane would provide a set of generic instructions that could decode and process \emph{any} header and field.

From there it is possible to achieve \textit{protocol oblivious processing}. By being able to program the packet processing functions, the data plane \textit{does not have to know about any standard protocols} (ethernet, IPv4, TCP, etc). Support for protocol headers is strictly left up to the programmer. This allows users to defined their own protocols in addition to supporting well-known protocols. This makes the data plane scalable, that is, there is no need to provide specific support for every possible protocol header.

The user can then define \textit{their own} customized \textit{packet processing pipeline}. A packet processing pipeline is a kind of algorithm for handling packets coming into a networking device. The pipeline is made up of small stages. Some stages decode packet headers, others make forwarding decisions based on forwarding rules installed in decision tables. In essence, the pipeline defines the behavior of the networking device. One pipeline may define a MAC forwarding switch, another might define an IP router.

The forwarding rules can be freely manipulated. Because protocol independence is also achieved, these rules can handle arbitrary headers. It opens the way to networking applications which can be tailor made for custom protocols \textit{without needing new hardware} to handle them.

By changing the program which drives the packet processing pipeline, the user can \textit{change the devices behavior without changing the device's hardware}.

The data plane can support arbitrary operations. Operations performed on a packet do not have to be limited by actions which are exclusive to specific protocols. Programmable data plane instruction sets can generically manipulate bites and perform operations like a CISC or RISC processor.

As one might see, there is a lot of value and flexibility to a programmable data plane. 

\section{What is Steve?}

That brings up the question, "What is Steve?" Steve is a high-level, protocol oblivious programming language for defining these packet processing pipelines on programmable data planes.

This paper proposes Steve a high level, protocol oblivious, programming language for defining a packet processing pipeline for a programmable data plane. Steve is a declarative language, not too different from C, making it rather familiar to all programmers.

Most importantly, Steve abstracts much of the low-level code a programmer would have to write. One could program a data plane in C or device-specific assembly, but this process forces the programmer to engage in low-level details such as resource acquisition, port interfaces, device configuration, hardware limitations, etc. Even worse, the user has to worry about manually decoding headers by specifying which bits make up a field. This can be an error-prone nightmare. This type of low-level programming is subject to undefined behavior, logical errors, program crashes, memory leakage, etc. This is unacceptable on important network devices,

Steve and its runtime system, Flowpath, abstract most of these details away from the programmer. Instead, the programmer only focuses on high level aspects such as defining the layout of headers, decoders, and a complete packet processing pipeline. The language compiler takes care of the rest.

\section{Contributions}

% FIXME: Contributions means "your contributions to the state of the art",
% not just what what you did in the project. I would focus this section on
 % aspects of the language related to safe and efficient pipeline description.

This thesis provides two major contributions: the Steve language features and the Steve-to-Flowpath compiler.

\subsection{Language Features}

Steve provides the following languages features for expressing a packet processing pipeline, each of which are the contributions proposed by this thesis.

\begin{itemize}
\item The ability to define the layout of any arbitrary header, thus making Steve protocol oblivious.

\item The ability to specify a flexible pipeline which handles packet processing and forwarding. This pipeline is composed of one or more decoders and flow tables.

\item The ability to define decoding stages, or decoders. Decoders allow programmers to find and extract specific fields from desired headers. They also provide the mechanics to reason about which packet header comes next based on conditions satisfied by the current packet header.

\item The ability to define flow tables. Flow tables provide a mechanism for making decisions about, or classifying, a packet based on decoded fields \cite{openflow_spec}. Flow tables contain rules known as flow entries which perform \textit{actions} on like-classified packets.

\item
Actions provide a way to modify a packet's fields, modify the state of a table, forward a packet, or drop a packet. They may also be used to move from decoders to flow tables, and vice-versa.
\end{itemize}

Using these language features to write a packet processing pipeline is the topic of Chapter \ref{ch:tutorial}: The Steve Tutorial.

\subsection{Steve Compiler}

The Steve-to-Flowpath compiler is responsible for converting Steve programs into application modules that are loadable by the Freeflow data plane runtime \cite{freeflow_software} described in Chapter \ref{ch:flowpath}. It provides certain safety guarantees by enforcing the semantics of the language and performing analysis on user-defined pipelines. This section is only a summary. Chapter \ref{ch:users_guide}: User's Guide explores the Steve language semantics in greater detail.

% FIXME: Skip the beaker references here. That's an implementation detail.
% Also, I think you need to introduce Steve as a concept before you start
% talking about its features.
Steve is a statically typed language and thus supports static type checking. This functionality is derived from the Beaker programming language \footnote{https://github.com/asutton/beaker/} which the Steve compiler is an extension of. In regards to packet processing, Steve allows the programmer to give static types to header fields. The Steve compiler makes sure those fields can only be used in operations valid for its given type.

The Steve compiler also ensures certain safety properties over the entire packet processing pipeline.

\begin{enumerate}
\item Fields that have not been extracted cannot be used. It is perfectly possible for a programmer to define a pipeline which uses a field, yet forgot to decode that field.

\item The pipeline is always a linear progression. The packet must always move from exactly one stage in the pipeline to exactly one other stage. It also prevents a packet from infinitely looping between stages in a pipeline.
\end{enumerate}
