\chapter{INTRODUCTION} \label{ch:intro}

% FIXME: The introduction needs to flow. Don't break it up into this kind of
% question and answer dialog, and don't skimp on motivation. Take this guy's
% PhD thesis as an example:
%
% http://www.cs.colostate.edu/~christos/thesis/chp1.pdf
%
% It's a little more detailed than you'll need, but it's a good example of
% how to motivate the problem and organize both the solution and your
% contributions.

% FIXME: Use \emph to emphasize terms, not boldface.

% FIXME: Use this sentence in your abstract.


Packet-switched networks have gone through an explosive evolution over the last half century. In the late 1960's, there was ARPANET which connected a sparse few computers across the globe using the early TCP/IP protocols. By the late 1980's, networks were becoming more and more accessible with the first Internet service providers starting up. As the 1990's began ARPANET was retired, but the new, modern Internet had arisen to take its place. From the 1990's to present day new protocols were produced which allowed for emails, instant messaging, voice communication, videos, and so forth to be sent over networks. 

The Internet, which is nowadays ubiquitous with everyday life, connecting millions of computers across the globe, continues to drive networking technology forward. The network hardware used to connect computers has evolved. Primitive wires and repeater hubs evolved into modern devices such as switches and routers.

These modern devices implement two fundamental components in their firmware, the control plane and the data plane. The control plane decides where packets should be sent and is capable of learning new forwarding behaviors over time. The control plane commands the data plane. The data plane actually moves the packets from port to port. Almost all modern networking devices continue to operate using this conventional model. However, firmware is rarely ever updated. The behavior thus rarely changes. These devices are dedicated to one singular task for the duration of their lifetime. This type of networking device can be considered \emph{hardware-defined networking}.

Over time this conventional type of networking became complex, rigid, and proprietary. These devices are built to handle an enormous amount of protocols. These protocols, however, can rarely evolve because devices cannot handle unexpected new header formats. Developers of these devices do not expose interfaces to the internals of the system leaving users with a black box which is both difficult to customize and hard to manage.

Due to these issues, a new paradigm for networking appeared. This new paradigm is called \textit{software-defined networking} (SDN). The Open Network Foundation (ONF) defines SDN as ``the physical separation of the network control plane from the forwarding plane, and where a control plane controls several devices \cite{onf_sdn_def}. In essence, the control plane is removed from the firmware. Instead, this part of the network device is implemented in software. This software control plane is capable of controlling several devices over a single network using messages. Much of the work into SDN has targeted OpenFlow \cite{openflow_spec}, an open-source standard for SDN switches. With open-source SDN, any programmer can write regular software on typical operating systems to customize the behavior of their networking device. 

However, the programmable control plane is only the \emph{first step}. The next step is the \emph{programmable data plane}. What benefits does this have?

Being able to customize packet processing functionality is the primary feature.
The data plane can support programmable packet parsers/decoders. Rather than relying on specialized hardware or firmware tailored towards decoding a massive suite of well-known protocol headers, the data plane would provide a set of generic instructions that a programmer could use to decode and process \emph{any} header and field.

From there it is possible to achieve \textit{protocol oblivious packet processing}. By being able to program the packet processing functions, the data plane \textit{does not have to know about any standard protocols} (ethernet, IPv4, TCP, etc). Support for protocol headers is strictly left up to the programmer. This allows users to define their own protocols in addition to supporting well-known protocols. This makes the data plane scalable, that is, it can adapt to new headers fairly easily.

The data plane can support arbitrary operations on packets. Operations are not specific to certain protocol fields. Instead, operations are \textit{generic}, that is, operations performed on one field can be performed on any field. For example, instead of having an operation exclusively for decrementing the IPv4 time-to-live field, the data plane would support generic arithmetic.

The programmer can customize a switch with customized packet processing applications and forwarding rules. Typically, this is done through an abstract model defined by OpenFlow called a \textit{packet processing pipeline} \cite{openflow_spec}. The pipeline makes decisions, performs operations, and applies forwarding rules on packets.

Forwarding rules can handle any header and can be user-defined. It opens the way to networking applications made for custom protocols and forwarding behaviors. By changing the program which drives the packet processing pipeline, the user can \textit{change the device's behavior without changing the device's hardware}. The same device can go from being a repeating hub to a MAC learning switch to a router just by running a different program on it.

Writing programs for these data planes is the next logical step. There must exist a programming language that any programmer can learn and write packet processing programs with. A number of these languages exist. Some attempt to solve this problem by providing APIs for existing programming languages. Others attempt to produce domain-specific \textit{SDN languages}. The Steve programming language is one of these SDN languages.

\section{Difficulty of Programming Data Planes}

Typical packet processing programs are written in low-level languages, most commonly C. These C programs usually work with data plane programming APIs such as Open Data Plane (ODP) \cite{odp_webpage} and the Data Plane Programming Kit (DPDK) \cite{dpdk_webpage}. Writing these programs can be difficult for a number of reasons.

Low-level packet processing code can be very light on easy to understand abstraction and very heavy on gritty implementation details. The programmer should be focusing on high-level abstractions; concepts such as: what fields are needed, what operations must be performed on these fields, conditional decision making, packet classification, etc. Instead, they are worried about the many common ailments of writing in low-level code.

The programmer must deal with resource allocation and management. They must deal with allocating their own buffers for storing packets and by extension must deal with de-allocating those buffers. This type of resource management is prone to accidental memory leakage, especially in C. Memory leakage of gigabytes of data will quickly bring a system down.

The programmer must directly manage ports. They are also responsible for manually receiving, reading, and sending packets on those ports. This is code is common to all packet processing applications. The programmer should not be burdened with this kind of common code when writing a packet processor.

When working with packet headers, the programmer must manually work with raw arrays of bytes. The burden of decoding fields from byte arrays and interpreting the value of those fields is shifted onto the programmer. Manual decoding can be a painful process on its own. It is prone to error, particularly off-by-N errors. When reinterpreting those bytes into header data structures, the result can be disastrous if the bytes are wrong or the data structure is wrong. Moving or copying those bytes around is particularly prone to buffer overflows.

A number of other common problems come up when working in low-level code. Undefined behavior from reading past the end of packet buffers can be one. Performing operations on null pointers, invalid pointers, or uninitialized memory is another.

Steve and its runtime, Flowpath, attempt to remedy most of these problems. The objective is to abstract many of these low-level details. Instead, the programmer only focuses on the high-level abstractions. Specifically, the Steve language focuses the programmer on writing the packet processing pipeline and makes the grittier details opaque.

\section{Contributions: A Language for Safe Packet Processing Pipelines}

Steve is a high-level SDN language for defining protocol oblivious packet processing pipelines for programmable data planes. Steve's packet processing pipelines are programs which provide packet decoding, manipulation, and forwarding functionalities. The language is easy to write and comprehend for new users. Most importantly it ensures efficiency, resource safety, type safety, and certain logical guarantees on all user-written pipelines.

\subsection{Language Features}

Steve language features provide all the necessary abstractions for processing packet headers.

\emph{Header layouts}. The Steve language provides a way for users to define the layout of headers. The user can define the fields contained within a header. The user provides types for those fields which: 1) provide the length of the field and 2) allow Steve type-checking to limit operations on those fields to only those safe for that type. Steve is protocol oblivious, and thus does not inherently support well-known headers. It is left up to the user to determine what fields they expect to work with.

\emph{An abstract pipeline model}. Steve adopts an abstract packet processing pipeline model which is a generalized version of that defined by OpenFlow \cite{openflow_spec}. The Steve pipeline is composed of two stages: decoders and flow tables. Decoders find and extract fields. Flow tables make decisions, perform actions, and forward packets. A packet entering the pipeline must first be decoded by at least one decoder. From there, stages may be flexibly interleaved. A series of decoders may be followed by a series of flow table matches which may lead into more decoders.

\emph{Decoders}. Decoders allow the user to decode and extract fields from a header. Decoders allow the user to specify which fields they need. Decoders do not require that a user extract all fields if they do not need those fields. The user is not required to manually extract the bytes associated with a field. Instead, the user gives a field name from the header layout they defined, and the language generates the code for them.

\emph{Flow tables}. A flow table, which is an OpenFlow abstraction, is a dynamic decision structure which classifies packets into flows. Each flow has a set of actions associated with it. Packets which are part of the same flow have those actions applied to them.

\emph{Actions}. Actions provide a way to modify a packet's fields, add/remove flows from tables, and forward/drop packets. Steve actions are a generalization of OpenFlow instructions and actions.

\subsection{Type Safety}


The Steve compiler also ensures certain safety properties over the entire packet processing pipeline.

\begin{enumerate}
\item Fields that have not been extracted cannot be used. It is perfectly possible for a programmer to define a pipeline which uses a field, yet forgot to decode that field.

\item The pipeline is always a linear progression. The packet must always move from exactly one stage in the pipeline to exactly one other stage. It also prevents a packet from infinitely looping between stages in a pipeline.
\end{enumerate}
