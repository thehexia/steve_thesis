\chapter{Steve Safety and Limitations} \label{ch:limits}

This chapter discusses the safety guarantees enforced in individual stages
and the pipeline as whole. It will also expand upon the limitations
briefly mentioned in the tutorial from Chapter \ref{ch:tutorial}.

\section{Pipeline Guarantees and Constraints} \label{guide:pipeline_checking}

Steve makes guarantees about the logical correctness and safety of pipeline
composition using a constraints system. These guarantees are enforced by ensuring each Steve pipeline has two properties: \textit{progress} and \textit{memory safety}. Any
pipeline which does not have these properties is ill-formed.

\subsection{Pipeline to Graph Conversion} \label{guide:pipeline_graph}

To check these properties, a directed graph, known as a \emph{transition graph}, is constructed over stage transitions within the pipeline.
Each property thus becomes a graph evaluation algorithm on this graph.

%Let the set of vertices $N$ represent stages in the pipeline: decoders, flow tables, flow entries, event handlers, egress processing, and termination.
Let the transition graph $G=(V, E)$ be defined as follows. $V$ is the set of vertices representing declarations of stages in the program: decoders, flow tables, and event handlers. $E$ is the set of edges derived from
\texttt{decode}, \texttt{goto}, and \texttt{raise} actions found in those definitions. There exists a directed edge $(s, d)$, where $s$ is the stage containing the action and $d$ is the destination stage.

%Flow entries and inserted flow entries are treated as independent vertices because they are separate branches in pipeline logic.
%Added flows cannot violate pipeline guarantees, regardless of when they get added.
%For each flow entry within a flow table or that would be inserted into a table, let there be a directed edge from the flow table to the flow entry.
%
%For every \texttt{decode}, \texttt{goto}, and \texttt{raise} action found in a stage
%(or flow entry within a table), let there be a directed edge from the stage
%to the destination specified by the action.
%This edge is added even if the action is encapsulated by a conditional statement
%because its impossible to determine during compile time whether or not that edge
%is reachable during runtime.
%
%Let there be a vertex in $e \in N$ which represents egress processing. For each stage which is not guaranteed to execute a stage transition action (\texttt{decode}, \texttt{goto}, and \texttt{raise}), let there be an edge from that stage to $e$. Let there be a vertex $t \in N$ which represents termination. There exists an edge from $e$ to $t$. For any \texttt{drop} action found within a stage, let there be an edge from that stage to $t$.

The Steve language defines exactly one entry point to the packet processing pipeline -- the starting decoder. Any vertex not reachable from the starting decoder is excluded from analysis since it will never be executed.

\subsection{Progress} \label{guide:progress}

The \textit{progress} property guarantees that packet processing always terminates. Though the syntax allows the programmer to construct pipelines that would not terminate, construction is restricted semantically.  Such guarantees are excluded for while loops and function calls due to the halting problem.

A Steve program terminates if and only if the transition graph is a directed acyclic graph (DAG), otherwise it contains cycles between stages which potentially result in non-termination.
%Steve transition graphs can be checked to determine that they terminate. 
To check this, simply generate a topological ordering of vertices in the stage transition graph. If no such order can be constructed, the pipeline does not guarantee progress (i.e., the graph admits a cycle), and the program is ill-formed.

%\emph{Proof.} It is obvious from the definition of DAG that pipeline processing must terminate.

%First of all, table vertices are assigned a hidden, unique, incremented integer identifier in the order with which they are declared. For example, the first table declared in a Steve program is given the integer identifier 0, the second table declare is given the identifier 1, and so on. Conventionally, tables are expected to be declared in the order with which they are expected to occur in a pipeline.
%
%The \textit{table identifiers} rule says that at no point in the pipeline can a packet reach a target table if it has already visited a table stage whose integer identifier is higher than or equal to that of the target table. In other words, a packet can only go forward through tables, never backwards. This is compliant with the OpenFlow specification for tables \cite{openflow_spec}. Because of this table identifiers rule, it is impossible for any number of table stages to form a cycle with each other.
%
%\textit{Proof.} A cycle can only be formed if the next table has either been visited, or is contained within a path to a table that has been visited. This can only happen if the next table has an identifier less than or equal to that of the current largest identifier visited. This property is enforced by the way tables are numbered. Since the table identifiers rule prevents a packet from being sent to these tables, it is thus impossible to form a cycle.

\subsection{Memory Safety} \label{guide:requirements}

The \emph{memory safety} property ensures that memory locations that are not declared or allocated by the program are not accessed. For packets, this means that packet memory must be checked to guarantee existence and valid construction. This work focuses on existence; previous Steve work focused on construction \cite{wripe}.
For a Steve program to be memory safe entails two properties:

\begin{enumerate}
\item Within a processing stage, a header field shall not be accessed unless it is required or extracted.
\item For each node in the transition graph, the requirements of the node shall have been previously extracted.
\end{enumerate}

In the first case, for a field to be used within a stage, the name must be in scope.
In a decoder, a field name is in scope after an extract declaration for that field.
Fields whose names are listed in an event handler's \texttt{requires} specifier are required by the stage. The scope of these names is the body of the event handler.
Similarly, field names listed in a flow table's key and \texttt{requires} specifier are required by the stage, and the scope of these names is the body of initial and inserted flow entries for that table.


%Within a decoder, a field may only be accessed after an extract declaration. Within a flow entry, a field may only be accessed if it appears in the table's key fields or \texttt{requires} specifier. Within an event handler, a field may only be accessed if it appears within the \texttt{requires} clause. In order to prove that these accesses are valid, it must be shown that field access can only happen if a vertex has its requirements satisfied.


%\textit{Requirement Satisfaction} checks that a field is accessed only after it has been extracted. This prevents accidental access of fields that have not been discovered or that do not exist. For example, consider the pipeline graph in Figure \ref{fig:bad_graph} which demonstrates an ill-formed pipeline where a field is required but not extracted.

In the second case, if a stage requires a field, it must be extracted in all paths leading to that stage.
For example, Figure \ref{fig:bad_graph} depicts an ill-formed pipeline where one path violates this property.

\begin{figure}[ht]
\includegraphics[width=0.85\textwidth]{bad_graph}
\caption{An ill-formed pipeline. Table \texttt{T1} requires fields A, B, and C. However, in the path from \texttt{D1} to \texttt{D3} to \texttt{T1}, field C has not been extracted.}
\label{fig:bad_graph}
\end{figure}

To check this,
every vertex in the transition graph is associated with a set of \textit{productions} and \textit{requirements}.
A production is a field that has been extracted or created by the vertex's respective stage. Only decoding stages have productions. If a field were pushed onto the packet, that would also constitute a production; however, this is not currently supported.
Fields in a stage's requirements are described in the first case. 

Let $G$ be the transition graph representing the Steve pipeline.
Let $P$ be the set of all paths from the root vertex (representing the starting decoder) to a vertex $v \in G$.
For a path $p \in P$, let $S$ be the union of all productions of vertices in $p$.
For $p$ to \emph{satisfy} the requirements of $v$,
the requirements of $v$ must be a subset of $S$.
If any $p \in P$ does not satisfy the requirements of $v$, then the program
is ill-formed. If all $v \in G$ have their requirements
satisfied, then the program is well-formed, otherwise it is ill-formed.

%\textit{Theorem.} Accessing a field can not happen before it has been extracted.
%
%\textit{Proof.}
%Within a decoder, a field may only be accessed after an extract declaration. Within a flow entry, a field may only be accessed if it appears in the table's key fields or \texttt{requires} specifier. Within an event handler, a field may only be accessed if it appears within the \texttt{requires} clause. In order to prove that these accesses are valid, it must be shown that field access can only happen if a vertex has its requirements satisfied.
%
%With a proof by contradiction, assume that field access happened within a vertex whose requirements were not satisfied, therefore the field has not been extracted. By definition of requirement satisfaction, the pipeline is ill-formed. Therefore, field access could not happen.

%The objective is to prevent field access on fields that have not been extracted. Field access can only be done in three cases. In case 1, the decoder accesses the field.
%In case 2, a flow entry within a table accesses the field. In case 3, an event
%handler accesses the field.
%
%In case 1, a decoder can only use a field after an extract declaration with
%that field name has been made inside that decoder. This innately prevents field access from happening on
%un-extracted fields within a decoder. Since a decoder can only access fields it has decoded, it also has no requirements that must be satisfied by other vertices.
%
%In case 2, the Steve language semantics prevent a flow entry from using
%fields that are not part of the containing flow table's key fields or
%required fields. If all paths leading to the table satisfy its requirements,
%by definition those fields must have been extracted at least once before
%reaching the table. If this is the case, when the flow entry accesses that
%field, it is guaranteed to have been extracted.
%
%In case 3, the Steve language semantics prevent an event handler from using fields
%that are not listed in the \texttt{requires} specifier. If all paths
%leading to an event handler satisfy its requirements, then by definition, it is guaranteed that field has been extracted at least once.

%\subsection{Requirements Checking Algorithm} \label{guide:dfs_desc}

To confirm that all vertices have their requirements satisfied, the Steve compiler uses depth-first traversal with backtracking to evaluate all possible paths in a pipeline graph (see Algorithm \ref{alg:dfs}).
This algorithm assumes that a graph is a DAG.
As the algorithm traverses a path, it accumulates a set of productions at each vertex, then confirms that the vertex's requirements are satisfied. Any vertex which fails immediately indicates the program is ill-formed and further traversal along that path stops.

%At any point in a given path, if a vertex's edge is directed toward a previously visited vertex in the path, e.g. a cycle is found, traversal past that vertex immediately stops and the program is considered ill-formed. This ensures that the \textit{progress} property is met.

Once the algorithm reaches the end of a path successfully, it backtracks to previous
vertices and explores other paths. When backtracking, the algorithm removes the productions of vertices that were left behind.

\begin{algorithm}[ht]
 \caption{Depth-first traversal with backtracking used to check if the program is ill-formed because a field is accessed but not extracted.}
 \label{alg:dfs}
 \begin{algorithmic}
 \State
 \State \textit{Input}: Let \textit{G} be the pipeline transition graph. Let \textit{v} be a vertex in \textit{G}. Let \textit{S} be the accumulated set of productions.
 \State \textit{Output}: If the program is ill-formed because a field is accessed but not extracted.
 \State

 \Function{DFS}{$G, v, S$}
 	\State v.visited = true
 	\State difference = S $\setminus$ v.productions
 	\State S = S $\cup$ v.productions
 	\If{v.requirements $\subseteq$ S}
 		\For{\textit{all} a \textit{in} G.adjacentNodes(v)}
 			\If{a.visited == false}
 				\State \Call{DFS}{G, a, S}
 			\Else
 				\State \Return ill-formed
 			\EndIf
 		\EndFor
	\Else
 		\State \Return ill-formed
 	\EndIf


 	\State v.visited = false \Comment{Reset the visited property so we can come down this vertex again in a different path.}

 	\State S = S $\setminus$ difference \Comment{Remove the productions of this vertex from the set of productions when backtracking.}
 \EndFunction
 \end{algorithmic}

\end{algorithm}

\textit{Theorem.} The worst case complexity of this algorithm is $O(v!)$ where $v$ is the number of vertices.

\textit{Complexity Proof.}  Assume a DAG has $v$ vertices. There are at most $v-1$ vertices adjacent to the root vertex. Each vertex adjacent to the root has at most $v-2$ vertices adjacent to it. This pattern continues until paths end in a sink. Thus the number of paths can be represented as $(v-1)(v-2)...1$ or $(v-1)!$. Therefore, the performance
is $O(v!)$.

Fortunately, this worst case performance is rarely ever achieved. Only the most dense pipeline graphs, where a vertex at each level is connected to every other possible vertex has this kind of performance. Packet processing graphs are typically closer to trees as branches only occur when determining what the next header is. These graphs are generally not very deep either as packets tend to have a very small number of headers.
Additionally, it is acceptable to incur performance penalties at compile time
to ensure safety at runtime.

\textit{Termination Proof.} By definition, a DAG has a finite number of unique paths, therefore, the algorithm must terminate if it takes every unique path exactly once.
%A unique path, by definition, is an ordered sequence of vertices that is distinct from all other paths.
%Let $V$ be the set of all vertices in the graph $G$.
%For a graph traversal algorithm to visit the same path more than once.
%
%Consider the base case.
%Let $s$ be the root vertex for the graph. By Steve semantics, there may only be one start vertex. Let $A$ be the set of vertices adjacent to $s$. If the edge from $s$ to any $a \in A$ has been traversed, it is not possible to move from $s$ to $a$, therefore, the same path cannot be traversed twice from $s$.
%
%Now considering the recursive case, let $v$ be any other vertex in the graph. By definition of a DAG, $v$ must be the root of some subgraph $G'$ in $G$ that is also a DAG. Let $A'$ be the set of adjacent vertices to $v$. For each vertex $a' \in A'$, the $DFS(G',v, p)$ traverses the edge from $v$ to $a'$ exactly once. If this algorithm does not terminate, then the algorithm must be able to traverse from $v$ to any vertex $a' \in A'$ more than once, which is not the case. Note that is is possible to apply the algorithm to $G'$ multiple times, but because there are a fixed number of paths from $s$ to a sink in $G$, it is executed a fixed number of times.

\section{Why Objects of Layout Type can not Exist.} \label{guide:no_dst}

It was mentioned in an earlier chapter than objects of layout type may not exist.
This is necessary for two reasons.
First, Steve does not currently support creating new packets or pushing new headers.
It can only process existing ones.
Objects of layout type are not strictly necessary without this ability.
Second, there are a number of concerns related to construction objects whose
types are dynamically sized.

Allocating objects of dynamically-sized types (DST) on the stack produce a number of concerns which have not been solved.
The only language which actually supports user-defined DSTs, Rust, only allows it under
very limited circumstance \cite{rust_dst_std}.
Allocating DST objects on the heap is, of course, what dynamic allocation was made for, but
it is expensive and does not help when reinterpreting existing packet memory.
Allocating a single DST object on the stack is not actually a difficult thing to achieve.
It is done by allocating memory by pushing the stack pointer forward using the intrinsic
\texttt{alloca}.
Now consider what happens when this DST object appears at the end of a class/record
type. For example:

\begin{lstlisting}
struct Ipv4 {
	version : uint(4);
	ihl : uint(4);
	// ...
	// options has dynamically-sized type predicated on ihl.
	options : DST(ihl);
}

var x : Ipv4 = ...;
\end{lstlisting}

The \texttt{options} member has a length predicated on the value
of another member in the object. In order to produce an object of type \texttt{Ipv4},
first the memory for the object must be allocated. Then the value of \texttt{ihl}
has to be evaluated. Then the memory for \texttt{options} can be allocated
using \texttt{alloca}. This is possible because \texttt{options} is the last member in the class. Though tricky, this is still possible and roughly what the Rust does.

However, now consider what happens when the DST member is \emph{not} at the end
of the class, but rather the middle. For example:

\begin{lstlisting}
struct FooClass {
	x : int;
	y : DST(x);
	z : int;
}
\end{lstlisting}

Only \texttt{x} can be allocated at first. The value of \texttt{x} has to be evaluated
and only then could \texttt{y} and \texttt{z} be allocated. It becomes impossible
for the compiler to reason about the actual position of \texttt{z} in memory. This
makes member access on \texttt{z} an extremely expensive runtime computation.
Then consider that an object of type \texttt{FooClass} may also appear in
another class, making it even more difficult to manage.

Because of these unclear issues, Steve has forgone allowing objects of DSTs.
By extension, because layouts have to have DST fields, objects of layout type
are also not allowed.


\section{Decoder Anatomy} \label{decoder_anatomy}

This section discusses the ``anatomy'' of a decoder.
Specifically, it will describe the formalism of \textit{(offset, length)} generation by the compiler.

\subsection{Determining the Location and Length of Extracted Fields}

An extract declaration produces an extraction by executing a set of instructions on a packet which saves the extraction's \textit{location} and \textit{length} to the context's binding environment. Information gathered from the field name and layout rule is used to calculate these two values. These instructions are completely opaque to the user and are automatically generated by the compiler. The formalism for this code generation is described below.

First, let the field name have the form \textit{E1.E2} where \textit{E1} is the \textit{container layout} and \textit{E2} is the \textit{contained field}.

\begin{enumerate}
\item The length of the extracted field is calculated by a function $len(E2)$. The result of $len(E2)$ is the \textit{size} of an object of $E2$'s type.

\item  Let $precede(E1, E2)$ be a function that returns the sequence of all field declarations preceding \textit{E2} in \textit{E1}.

\item The function used to calculate the \textit{relative offset} of $E2$ is given as $rel(E1, E2)$ and is defined as:

\begin{enumerate}

\item If \textit{E1} identifies a layout, then $rel(E1, E2) = \sum_{x \in precede(E1,E2)}{} len(x)$.

\item If \textit{E1} is a field name, then let \textit{E1} have the form \textit{E1'}.\textit{E2'}.

Then $rel(E1, E2)=rel(E1', E2') + \sum_{x \in precede(E2',E2)}{} len(x)$

\end{enumerate}

\item If $rel(E1, E2)$ results in a number greater than the length of the packet, then the packet is malformed and dropped.

\item Given a field name of the form \textit{E1.E2} and the current view index (see \ref{guide:decoder_view}), $i$, the \textit{absolute offset} of the field being extracted is $abs(E1, E2) = i + rel(E1, E2)$.
If the result of $abs(E1, E2)$ is greater than the length of the packet, then the packet is malformed and dropped.

\item The location of an extracted field is its absolute offset, that is, the number of bits (or bytes) it is away from the beginning of the packet. The pair stored by the binding environment is $(abs(E1, E2), len(E2))$.

\end{enumerate}

Consider the following example. Two layouts, \texttt{L} and \texttt{N}, and a decoder, \texttt{D}, are provided.

\begin{lstlisting}
layout L {
	a : uint;
	b : uint;
	c : N;
}
layout N {
	d : uint(8);
	f : uint(16);
}
decoder D(L) {
	extract L.a;
	extract L.c.f;
}
\end{lstlisting}

\texttt{L} has three fields: \texttt{a}, \texttt{b}, and \texttt{c}.  \texttt{N} has two fields: \texttt{d} and \texttt{f}. Field \texttt{L.c} has layout type \texttt{N} and is thus a nested layout. \texttt{D} decodes \texttt{L} and extracts \texttt{L.a} and \texttt{L.c.f}.

The first extract declaration is \texttt{extract L.a}. The type of \texttt{a} is \texttt{uint} (32 bit unsigned integer by default). The result of $len(a)$ is 32 bits or 4 bytes. The relative offset of \texttt{a} in \texttt{L} is the sum of the lengths of all field declaration which precede it. In this case, no fields precede it, thus its relative offset is 0.

The second extract declaration is \texttt{extract L.c.f}. This is the case of the nested layout. The value of $len(f)$ is 16 bits or 2 bytes. The relative offset of \texttt{f} is the sum of the length of all field declaration which precede it in \texttt{N} (8 bits or 1 byte), plus the relative offset of \texttt{c} in \texttt{L} (64 bits or 8 bytes). Thus, the relative offset for \texttt{L.c.f} is $64+8=72$ bits or 9 bytes.

Assuming an arbitrary example where the beginning of the current view for \texttt{D} is 112 bits past the beginning of the packet, the \textit{absolute offset} for \texttt{L.a} would be 112 bits. The absolute offset for \texttt{L.c.f} would be $112+72=184$ bits or 23 bytes.

\subsection{Extracting the Same Field More Than Once}

A common misunderstand happens when an extract appears within a loop.
A decoder is only ever looking at one header of a packet at once. Using an extract declaration with the same field name more than once in the same decoder will result in the same instance of that field being extracted multiple times, which is completely redundant. Though legal, this should be avoided in most cases. For example:

\begin{lstlisting}
while (x < 5)
	extract L1.f1;
\end{lstlisting}

%The extractions which \texttt{N1} can refer to are a subset of the extractions \texttt{N2} can refer to. The aliased name naturally can refer to extractions which are from a different kind of field than the original name. To demonstrate this, the following revision is made to the prior example:
%
%\begin{minip}
%\begin{lstlisting}
%decoder D1(L1) {
%	extract L1.a;
%	if (L1.a == 0)
%		goto T1;
%
%	decode d2;
%}
%
%decoder D2(L2) {
%	extract L2.c as L1.a;
%	// Valid usage of L2.c.
%	var i : uint(16) = L2.c;
%	// Valid usage of L1.a to refer to the same extraction.
%	var j = uint(16) = L1.a;
%
%	set L2.c = 1;
%	goto T1;
%}
%
%// Key field L1.a will refer to the last extraction of L1.a.
%// If D1 sends the packet to T1, then it will be the L1.a field.
%//
%// If D2 sends the packet to T1, then L1.a shall refer to an
%// extraction of L2.c instead.
%exact_table T1(L1.a) {
%	{ 0 } -> { drop; }
%	{ 1 } -> { flood; }
%}
%\end{lstlisting}
%\end{minip}
%
%This example presents decoders \texttt{D1} and \texttt{D2}. If a packet is sent directly to table \texttt{T1} from decoder \texttt{D1}, the value of the last extraction of \texttt{L1.a} will be \texttt{0} (based on the \texttt{if} condition). In this scenario, the packet is dropped.
%
%However, if the packet is sent from decoder \texttt{D2}, the field \texttt{L2.c} has been aliased as \texttt{L1.a}. The field \texttt{L2.c} has its value set to \texttt{1}. \texttt{L1.a} refers to the same value as L2.c because of the rebinding, therefore, the value of L1.a is also \texttt{1}.
%When the packet is matched against \texttt{T1}'s flow entries, the packet shall be flooded.
%
%Supposing table \texttt{T1} from the prior example were replaced with the following version of \texttt{T1}, then the \texttt{goto T1} action in decoder \texttt{D1} would actually produce a compiler error for violating requirements satisfaction (see \ref{guide:requirements}).
%
%\begin{minip}
%\begin{lstlisting}
%exact_table T1(L2.c) { ... }
%\end{lstlisting}
%\end{minip}
%
%This version of \texttt{T1} uses \texttt{L2.c} as a key field. However, \texttt{L1.a} is not the same field as \texttt{L2.c} and has not been aliased as such.
